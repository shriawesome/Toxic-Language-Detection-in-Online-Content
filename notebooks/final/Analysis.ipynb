{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "- The purpose of this notebook is to do comparitive analysis of three algorithms: Naive Bayes, Logistic Regression and Support Vector Machines for combinations of n-gram range and TFIDF norm values.\n",
    "- This is done to select the appropriate value of 'n' in n-grams and to select the better norm for TFIDF.\n",
    "- Two algorithms giving the best results will be considered as baseline algorithms.\n",
    "- The hyperparameters of these algorithms will be tuned to further improve the results. The tuned-model with the best results will be finalized for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "The dataset used here is a combination of three twitter datasets which were rated by human raters for toxicity. There exist two files, train.csv and test.csv for training and testing respectively.\n",
    "\n",
    "Hence the comments are tagged in the following three categories\n",
    "\n",
    " - Hate Speech\n",
    " - Offensive\n",
    " - Clean\n",
    " \n",
    "The tagging was done via crowdsourcing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47edabbdc3ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msettings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data.preprocess_data import *\n",
    "from nltk.stem.porter import *\n",
    "from settings import *\n",
    "from visualization.visualize import *\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA\n",
    "### Read dataset and take a peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA, index_col=False, lineterminator='\\n')\n",
    "df_test = pd.read_csv(TEST_DATA, index_col=False, lineterminator='\\n')\n",
    "print(df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data size:\", df_train.shape)\n",
    "print(\"Test data size: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the number of samples belonging to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data class distribution: \", df_train.groupby('output_class').size())\n",
    "print(\"Test data class distribution: \", df_test.groupby('output_class').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison of algorithms w.r.t diferrent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['text'].values\n",
    "Y_train = df_train['output_class'].values\n",
    "\n",
    "X_test = df_test['text'].values\n",
    "Y_test = df_test['output_class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Naive Bayes algorithm iteratively for different sets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_nb = [\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "]\n",
    "nb_clf = Pipeline(estimators_nb)\n",
    "\n",
    "param_grid = dict(\n",
    "    vect__ngram_range = [(1, 1), (1, 2), (1, 3)],\n",
    "    tfidf__norm = ['l1', 'l2']\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=23)\n",
    "gs_nb_clf = GridSearchCV(nb_clf, param_grid=param_grid, n_jobs=-1, cv=kfold, scoring='accuracy')\n",
    "     \n",
    "start = time.time()\n",
    "gs_nb_clf = gs_nb_clf.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "     \n",
    "with open(\"../../models/gs_nb_features.pkl\", 'wb') as gs_nb_clf_file:\n",
    "    pickle.dump(gs_nb_clf, gs_nb_clf_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression algorithm iteratively for different sets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_lr = [\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression())\n",
    "]\n",
    "lr_clf = Pipeline(estimators_lr)\n",
    "\n",
    "param_grid = dict(\n",
    "    vect__ngram_range = [(1, 1), (1, 2), (1, 3)],\n",
    "    tfidf__norm = ['l1', 'l2']\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=23)\n",
    "gs_lr_clf = GridSearchCV(lr_clf, param_grid=param_grid, n_jobs=-1, cv=kfold, scoring='accuracy')\n",
    "\n",
    "start = time.time()\n",
    "gs_lr_clf = gs_lr_clf.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "\n",
    "with open(\"../../models/gs_lr_features.pkl\", 'wb') as gs_lr_clf_file:\n",
    "    pickle.dump(gs_lr_clf, gs_lr_clf_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Support Vector Machine iteratively for different sets of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_svm = [\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(tol=None, max_iter=100))\n",
    "]\n",
    "svm_clf = Pipeline(estimators_svm)\n",
    "\n",
    "param_grid = dict(\n",
    "    vect__ngram_range = [(1, 1), (1, 2), (1, 3)],\n",
    "    tfidf__norm = ['l1', 'l2']\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=23)\n",
    "gs_svm_clf = GridSearchCV(svm_clf, param_grid=param_grid, n_jobs=-1, cv=kfold, scoring='accuracy')\n",
    "\n",
    "start = time.time()\n",
    "gs_svm_clf = gs_svm_clf.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "\n",
    "with open(\"../../models/gs_svm_features.pkl\", 'wb') as gs_svm_clf_file:\n",
    "    pickle.dump(gs_svm_clf, gs_svm_clf_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot line graph of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../models/gs_nb_features.pkl\", 'rb') as gs_nb_clf_file:\n",
    "    gs_nb_clf = pickle.load(gs_nb_clf_file)\n",
    "with open(\"../../models/gs_lr_features.pkl\", 'rb') as gs_lr_clf_file:\n",
    "    gs_lr_clf = pickle.load(gs_lr_clf_file)\n",
    "with open(\"../../models/gs_svm_features.pkl\", 'rb') as gs_svm_clf_file:\n",
    "    gs_svm_clf = pickle.load(gs_svm_clf_file)\n",
    "\n",
    "x = list()\n",
    "params = gs_nb_clf.cv_results_['params']\n",
    "for param in params:\n",
    "    norm = \"TDIDF norm: \" + str(param['tfidf__norm'])\n",
    "    ngram_range = \"N-gram range\" + str(param['vect__ngram_range'])\n",
    "    x.append(norm + \"\\n\" + ngram_range)\n",
    "    \n",
    "nb_means = gs_nb_clf.cv_results_['mean_test_score']\n",
    "lr_means = gs_lr_clf.cv_results_['mean_test_score']\n",
    "svm_means = gs_svm_clf.cv_results_['mean_test_score']\n",
    "y = [nb_means, lr_means, svm_means]\n",
    "\n",
    "draw_performance_comparison(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows all the three algorithms perform better for 'l2' norm of TFIDF. Futhermore, Naive Bayes and Logistic Regression show better performance than SVM for 'l2' norm. Therefore, we consider Naive Bayes and Logistic Regression for TFIDF norm 'l2' and N-gram range (1, 3) as baseline algorithms and tune their hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_nb = [\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('tfidf', TfidfTransformer(norm='l2')),\n",
    "    ('clf', MultinomialNB())\n",
    "]\n",
    "nb_clf = Pipeline(estimators_nb)\n",
    "\n",
    "param_grid = dict(\n",
    "    clf__alpha = [0.01, 0.1, 1, 10],\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=23)\n",
    "gs_nb_clf = GridSearchCV(nb_clf, param_grid=param_grid, n_jobs=-1, cv=kfold, scoring='accuracy')\n",
    "     \n",
    "start = time.time()\n",
    "gs_nb_clf = gs_nb_clf.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "     \n",
    "with open(\"../../models/gs_nb_tuned.pkl\", 'wb') as gs_nb_clf_file:\n",
    "    pickle.dump(gs_nb_clf, gs_nb_clf_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB Results\n",
    "with open(\"../../models/gs_nb_tuned.pkl\", 'rb') as gs_nb_clf_file:\n",
    "    gs_nb_clf = pickle.load(gs_nb_clf_file)\n",
    "\n",
    "x = list()\n",
    "params = gs_nb_clf.cv_results_['params']\n",
    "for param in params:\n",
    "    alpha = \"alpha: \" + str(param['clf__alpha'])\n",
    "    x.append(alpha)\n",
    "    \n",
    "nb_means = gs_nb_clf.cv_results_['mean_test_score']\n",
    "y = nb_means\n",
    "\n",
    "draw_hp_performance_nb(x, y)\n",
    "    \n",
    "print(\"Best: %f using %s\" % (gs_nb_clf.best_score_, gs_nb_clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_lr = [\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('tfidf', TfidfTransformer(norm='l2')),\n",
    "    ('clf', LogisticRegression(class_weight='balanced'))\n",
    "]\n",
    "lr_clf = Pipeline(estimators_lr)\n",
    "\n",
    "param_grid = dict(\n",
    "    clf__C = [10, 100],\n",
    "    clf__solver = ['newton-cg', 'liblinear', 'saga']\n",
    ")\n",
    "kfold = KFold(n_splits=10, random_state=23)\n",
    "gs_lr_clf = GridSearchCV(lr_clf, param_grid=param_grid, n_jobs=-1, cv=kfold, scoring='accuracy')\n",
    "\n",
    "start = time.time()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    gs_lr_clf = gs_lr_clf.fit(X_train, Y_train)\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "\n",
    "with open(\"../../models/gs_lr_tuned.pkl\", 'wb') as gs_lr_clf_file:\n",
    "    pickle.dump(gs_lr_clf, gs_lr_clf_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR Results\n",
    "with open(\"../../models/gs_lr_tuned.pkl\", 'rb') as gs_lr_clf_file:\n",
    "    gs_lr_clf = pickle.load(gs_lr_clf_file)\n",
    "    \n",
    "x = list()\n",
    "params = gs_lr_clf.cv_results_['params']\n",
    "for param in params:\n",
    "    C = \"C: \" + str(param['clf__C'])\n",
    "    solver = \"Solver: \" + str(param['clf__solver'])\n",
    "    x.append(C + \"\\n\" + solver)\n",
    "    \n",
    "lr_means = gs_lr_clf.cv_results_['mean_test_score']\n",
    "y = lr_means\n",
    "\n",
    "draw_hp_performance_lr(x, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (gs_lr_clf.best_score_, gs_lr_clf.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
